{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Climate CSV Data\n",
    "\n",
    "This program takes the climate CSV files produced by the DCM, cleans it up (e.g. by adding column names and removing unnecessary iterations), and produces JSONs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for jsonifying the CSV data\n",
    "\n",
    "# Read in csv and return processed dataframe\n",
    "def read_csv(file_name, dir, column_names, start_year, end_year):\n",
    "    # Read the CSV into a pandas dataframe without headers\n",
    "    file_path = os.path.join(dir, file_name)\n",
    "    df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "    # Rename columns in df\n",
    "    df.columns = column_names\n",
    "\n",
    "    # Add year column\n",
    "    num_timestamps = end_year - start_year + 1\n",
    "    df['year'] = (df.index % num_timestamps) + start_year\n",
    "    return df\n",
    "\n",
    "\n",
    "# Write dataframe to both csv and json output\n",
    "def save(df, file_name, output_dir):\n",
    "    output_csv_path = os.path.join(output_dir, 'csv', file_name)\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    output_json_path = os.path.join(output_dir, file_name).replace('.csv', '.json')\n",
    "    with open(output_json_path, 'w') as file:\n",
    "        json.dump({col: df[col].tolist() for col in df.columns}, file)\n",
    "\n",
    "\n",
    "# Read 'pos_generative.csv' and outputs formatted CSV and JSON\n",
    "def clean_pos_generative(file_name, dir, output_dir, column_names, start_year, end_year):\n",
    "    # Read in data\n",
    "    df = read_csv(file_name, dir, column_names, start_year, end_year)\n",
    "\n",
    "    # Remove all of the intermediate model data\n",
    "    num_timestamps = end_year - start_year + 1\n",
    "    df = df.tail(num_timestamps)\n",
    "\n",
    "    # Write to output directory\n",
    "    save(df, file_name, output_dir)\n",
    "\n",
    "\n",
    "# Read pos_generative_rand.csv\n",
    "def clean_pos_generative_rand(file_name, dir, output_dir, column_names, start_year, end_year, n):\n",
    "    df = read_csv(file_name, dir, column_names, start_year, end_year)\n",
    "    num_timestamps = end_year - start_year + 1\n",
    "    df = df.tail(n * num_timestamps)\n",
    "    df['run'] = ((df.index % (n * num_timestamps)) // num_timestamps) + 1  # each run is a different sampling of model params\n",
    "    save(df, file_name, output_dir)\n",
    "\n",
    "\n",
    "# Read 'true_generative.csv'\n",
    "def clean_true_generative(file_name, dir, output_dir, column_names, start_year, end_year):\n",
    "    df = read_csv(file_name, dir, column_names, start_year, end_year)\n",
    "    save(df, file_name, output_dir)\n",
    "\n",
    "\n",
    "# Read 'prior_generative.csv'\n",
    "def clean_prior_generative(file_name, dir, output_dir, column_names, start_year, end_year):\n",
    "    df = read_csv(file_name, dir, column_names, start_year, end_year)\n",
    "    save(df, file_name, output_dir)\n",
    "\n",
    "\n",
    "# Read 'prior_generative_rand.csv' TODO\n",
    "def clean_prior_generative_rand(file_name, dir, output_dir, column_names, start_year, end_year, n):\n",
    "    df = read_csv(file_name, dir, column_names, start_year, end_year)\n",
    "    num_timestamps = end_year - start_year + 1\n",
    "    df['run'] = (df.index // num_timestamps) + 1  # each run is a different sampling\n",
    "    save(df, file_name, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jsonify the data\n",
    "\n",
    "# Input directory\n",
    "input_dir = 'data/climate/ssp585/'\n",
    "\n",
    "# DCM input data\n",
    "start_year, end_year = 1750, 2100\n",
    "n = 10  # No. samples\n",
    "species = [\"CO2_FFI\", \"CO2_AFOLU\", \"CO2\", \"CH4\", \"N2O\"]  # species list\n",
    "\n",
    "# Construct column names\n",
    "emissions_cols = [f\"{s}_emissions\" for s in species]\n",
    "concentrations_cols = [f\"{s}_concentration\" for s in species]\n",
    "forcings_cols = [f\"{s}_forcing\" for s in species]\n",
    "temp_cols = ['atmospheric_temp', 'sea_layer1_temp', 'sea_layer2_temp', 'sea_layer3_temp']\n",
    "airborne_emissions_cols = [f\"{s}_airborne_emissions\" for s in species]\n",
    "column_names = emissions_cols + concentrations_cols + forcings_cols + temp_cols + airborne_emissions_cols\n",
    "\n",
    "# Prepare output directory\n",
    "output_dir = os.path.join(input_dir, 'clean')\n",
    "if not os.path.isdir(os.path.join(output_dir, 'csv')):\n",
    "    os.mkdir(os.path.join(output_dir, 'csv'))\n",
    "\n",
    "# Parse and clean CSV data\n",
    "clean_pos_generative('pos_generative.csv', input_dir, output_dir, column_names, start_year, end_year)\n",
    "clean_pos_generative_rand('pos_generative_rand.csv', input_dir, output_dir, column_names, start_year, end_year, n)\n",
    "clean_true_generative('true_generative.csv', input_dir, output_dir, column_names, start_year, end_year)\n",
    "clean_prior_generative('prior_generative.csv', input_dir, output_dir, column_names, start_year, end_year)\n",
    "clean_prior_generative_rand('prior_generative_rand.csv', input_dir, output_dir, column_names, start_year, end_year, n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
